{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intention Classification with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(series):\n",
    "    def delimit(sent):\n",
    "        arr = sent.split()\n",
    "        if arr:\n",
    "            arr.insert(0, '<START>')\n",
    "            arr.append('<END>')\n",
    "        else:\n",
    "            arr = ['<EMPTY>']\n",
    "        return arr\n",
    "    return series.apply(delimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(sents):\n",
    "    word_to_idx = {'<PAD>':0}\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = len(word_to_idx)\n",
    "                \n",
    "    vocab = set(word_to_idx.keys())\n",
    "    idx_to_word = {idx:word for word, idx in word_to_idx.items()}\n",
    "    return vocab, word_to_idx, idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_act</th>\n",
       "      <th>utterance_t-3</th>\n",
       "      <th>utterance_t-2</th>\n",
       "      <th>utterance_t-1</th>\n",
       "      <th>utterance_t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2121_1</th>\n",
       "      <td>bc</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Okay, ,, uh, &lt;END&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121_2</th>\n",
       "      <td>qw</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Okay, ,, uh, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, could, you, tell, me, what, you, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121_3</th>\n",
       "      <td>h</td>\n",
       "      <td>[&lt;EMPTY&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Okay, ,, uh, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, could, you, tell, me, what, you, thi...</td>\n",
       "      <td>[&lt;START&gt;, Well, ,, it, 's, hard, to, say, ., &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121_4</th>\n",
       "      <td>s</td>\n",
       "      <td>[&lt;START&gt;, Okay, ,, uh, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, could, you, tell, me, what, you, thi...</td>\n",
       "      <td>[&lt;START&gt;, Well, ,, it, 's, hard, to, say, ., &lt;...</td>\n",
       "      <td>[&lt;START&gt;, I, mean, ,, while, it, 's, certainly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121_5</th>\n",
       "      <td>qo</td>\n",
       "      <td>[&lt;START&gt;, could, you, tell, me, what, you, thi...</td>\n",
       "      <td>[&lt;START&gt;, Well, ,, it, 's, hard, to, say, ., &lt;...</td>\n",
       "      <td>[&lt;START&gt;, I, mean, ,, while, it, 's, certainly...</td>\n",
       "      <td>[&lt;START&gt;, What, do, you, think, ?, &lt;END&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dialog_act                                      utterance_t-3  \\\n",
       "utterance_ID                                                                 \n",
       "2121_1               bc                                          [<EMPTY>]   \n",
       "2121_2               qw                                          [<EMPTY>]   \n",
       "2121_3                h                                          [<EMPTY>]   \n",
       "2121_4                s                      [<START>, Okay, ,, uh, <END>]   \n",
       "2121_5               qo  [<START>, could, you, tell, me, what, you, thi...   \n",
       "\n",
       "                                                  utterance_t-2  \\\n",
       "utterance_ID                                                      \n",
       "2121_1                                                [<EMPTY>]   \n",
       "2121_2                                                [<EMPTY>]   \n",
       "2121_3                            [<START>, Okay, ,, uh, <END>]   \n",
       "2121_4        [<START>, could, you, tell, me, what, you, thi...   \n",
       "2121_5        [<START>, Well, ,, it, 's, hard, to, say, ., <...   \n",
       "\n",
       "                                                  utterance_t-1  \\\n",
       "utterance_ID                                                      \n",
       "2121_1                                                [<EMPTY>]   \n",
       "2121_2                            [<START>, Okay, ,, uh, <END>]   \n",
       "2121_3        [<START>, could, you, tell, me, what, you, thi...   \n",
       "2121_4        [<START>, Well, ,, it, 's, hard, to, say, ., <...   \n",
       "2121_5        [<START>, I, mean, ,, while, it, 's, certainly...   \n",
       "\n",
       "                                                    utterance_t  \n",
       "utterance_ID                                                     \n",
       "2121_1                            [<START>, Okay, ,, uh, <END>]  \n",
       "2121_2        [<START>, could, you, tell, me, what, you, thi...  \n",
       "2121_3        [<START>, Well, ,, it, 's, hard, to, say, ., <...  \n",
       "2121_4        [<START>, I, mean, ,, while, it, 's, certainly...  \n",
       "2121_5                [<START>, What, do, you, think, ?, <END>]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = ['utterance_ID', 'dialog_act', 'utterance_t-3', \n",
    "           'utterance_t-2', 'utterance_t-1', 'utterance_t']\n",
    "\n",
    "utt = pd.read_csv('da_tagging/utterances.train', sep='\\t|;',\n",
    "                  engine='python', names=COLUMNS, dtype=str).set_index('utterance_ID')\n",
    "utt[COLUMNS[2:]] = utt[COLUMNS[2:]].apply(preprocess)\n",
    "utt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = utt['utterance_t-3'] + utt['utterance_t-2'] + utt['utterance_t-1'] + utt['utterance_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(utt['dialog_act'].unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = utt['utterance_t'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = lens.max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.200466153016254"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_len = lens.mean()\n",
    "av_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the vast majority of sentence are shorter than the average length, 11, times 2. As such, we'll set our embedding dimension to this length, 22, as it it significantly shorter than the length of the longest sentence, 106."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051816266501105"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lens[lens < av_len * 2]) / len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, word_to_idx, idx_to_word = get_vocab(utt['utterance_t'])\n",
    "label_to_idx = {label:idx for idx, label in enumerate(utt['dialog_act'].unique())}\n",
    "label_to_idx['<PAD>'] = len(label_to_idx)\n",
    "embeds = nn.Embedding(len(vocab), max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_idx['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentNet(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes,\n",
    "                 batch_size=1, num_lstm_units=100, num_layers=100):\n",
    "        super(IntentNet, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_lstm_units = num_lstm_units\n",
    "        self.num_layers = num_layers\n",
    "        self._padding_idx = label_to_idx['<PAD>']\n",
    "\n",
    "        self.embeds = torch.nn.Embedding(len(vocab),\n",
    "                                         hidden_dim,\n",
    "                                         padding_idx=self._padding_idx)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n",
    "                            batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.embeds(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeddings.view(self.batch_size, len(sentence), self.embedding_dim),\n",
    "                            self.hidden)\n",
    "        label_space = self.output(lstm_out.view(len(sentence), -1))\n",
    "        scores = F.log_softmax(label_space, dim=1)\n",
    "        return scores\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hiddens = (torch.ones(self.num_layers, self.batch_size,\n",
    "                              self.num_lstm_units),\n",
    "                   torch.zeros(self.num_layers, self.batch_size,\n",
    "                               self.num_lstm_units))\n",
    "        return [Variable(h) for h in hiddens]\n",
    "\n",
    "net = IntentNet(max_len, 100, len(vocab) - 1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, learning_rate,\n",
    "          epochs, batch_size, momentum=0.9,gpu=True):\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for sentence, label in zip(X_train, y_train):\n",
    "            model.zero_grad()\n",
    "            model.init_hidden()\n",
    "\n",
    "            sentence = [word_to_idx[word] for word in sentence]\n",
    "            label = label_to_idx[label]\n",
    "            \n",
    "            if gpu and torch.cuda.is_available():\n",
    "                inputs = Variable(torch.cuda.LongTensor(sentence))\n",
    "                labels = Variable(torch.cuda.LongTensor(label))\n",
    "            else:\n",
    "                inputs = Variable(torch.LongTensor(sentence))\n",
    "                labels = Variable(torch.LongTensor(label))\n",
    "\n",
    "            scores = model(inputs)\n",
    "            print(scores)\n",
    "            loss = loss_func(scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Train accuracy: %{.2*train_accuracy},',\n",
    "                  f'Train loss: %{.2*train_loss}, Dev accuracy: %{.2*dev_accuracy},',\n",
    "                  f'Dev loss: %{.2*dev_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4977, -3.5731, -3.4872, -3.3413, -3.3871, -3.4568, -3.3737, -3.5281,\n",
      "         -3.4291, -3.4942, -3.4157, -3.2824, -3.3779, -3.4641, -3.3137, -3.3553,\n",
      "         -3.5805, -3.4375, -3.4779, -3.4797, -3.4977, -3.3642, -3.4252, -3.4324,\n",
      "         -3.5045, -3.4370, -3.4822, -3.3114, -3.5260, -3.3440, -3.4642],\n",
      "        [-3.5163, -3.5681, -3.5454, -3.3065, -3.3838, -3.4045, -3.4103, -3.5563,\n",
      "         -3.4058, -3.4538, -3.5031, -3.2738, -3.3807, -3.4969, -3.2639, -3.3181,\n",
      "         -3.6483, -3.4625, -3.4832, -3.5088, -3.4956, -3.3426, -3.4101, -3.4082,\n",
      "         -3.4780, -3.4079, -3.5407, -3.2829, -3.5068, -3.3707, -3.4538],\n",
      "        [-3.5369, -3.5609, -3.5843, -3.2959, -3.3909, -3.3865, -3.4210, -3.5704,\n",
      "         -3.3938, -3.4337, -3.5457, -3.2710, -3.3916, -3.5135, -3.2426, -3.2915,\n",
      "         -3.6727, -3.4718, -3.4839, -3.5178, -3.5025, -3.3205, -3.4023, -3.3919,\n",
      "         -3.4650, -3.3876, -3.5814, -3.2781, -3.4874, -3.3869, -3.4426],\n",
      "        [-3.5017, -3.6305, -3.4414, -3.3885, -3.4642, -3.5003, -3.2494, -3.6440,\n",
      "         -3.5072, -3.5064, -3.4833, -3.1912, -3.3549, -3.5624, -3.3514, -3.2348,\n",
      "         -3.4813, -3.4443, -3.5515, -3.5126, -3.5631, -3.2734, -3.3413, -3.4170,\n",
      "         -3.5747, -3.4285, -3.5458, -3.3219, -3.3970, -3.3167, -3.4774],\n",
      "        [-3.5238, -3.4806, -3.4326, -3.4504, -3.3660, -3.5353, -3.3085, -3.4484,\n",
      "         -3.4910, -3.5680, -3.5191, -3.2104, -3.2590, -3.4319, -3.3674, -3.4001,\n",
      "         -3.4949, -3.4865, -3.6245, -3.3162, -3.7284, -3.2064, -3.4145, -3.4533,\n",
      "         -3.5853, -3.3240, -3.6814, -3.4165, -3.3586, -3.2430, -3.5815],\n",
      "        [-3.4914, -3.4934, -3.4517, -3.3239, -3.4057, -3.4660, -3.3816, -3.5314,\n",
      "         -3.4534, -3.5759, -3.3361, -3.2793, -3.3969, -3.3954, -3.3952, -3.3560,\n",
      "         -3.4854, -3.3139, -3.4594, -3.2758, -3.5462, -3.3853, -3.4221, -3.4312,\n",
      "         -3.5214, -3.4145, -3.5841, -3.5854, -3.5654, -3.3774, -3.4677],\n",
      "        [-3.5212, -3.4950, -3.4812, -3.4199, -3.3973, -3.5601, -3.2647, -3.4879,\n",
      "         -3.4131, -3.6391, -3.3224, -3.2228, -3.4153, -3.3575, -3.4404, -3.4555,\n",
      "         -3.4878, -3.4060, -3.4278, -3.3454, -3.5450, -3.3059, -3.4448, -3.4642,\n",
      "         -3.6232, -3.5185, -3.5239, -3.3341, -3.4968, -3.3623, -3.4148],\n",
      "        [-3.5608, -3.5735, -3.4109, -3.4415, -3.4280, -3.5870, -3.2708, -3.5011,\n",
      "         -3.5000, -3.5878, -3.2117, -3.2843, -3.3811, -3.3700, -3.4572, -3.3660,\n",
      "         -3.3805, -3.3891, -3.4539, -3.3560, -3.6122, -3.3753, -3.4189, -3.4839,\n",
      "         -3.5281, -3.4338, -3.4656, -3.4763, -3.5448, -3.2932, -3.4591]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (8) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7c2dab6ef496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dialog_act'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-aa1f01f5a55f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, learning_rate, epochs, batch_size, momentum, gpu)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1788\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (8) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "train(net, merged, utt['dialog_act'], .01, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

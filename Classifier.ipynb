{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -keras\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import keras\n",
    "from utils import *\n",
    "from models.lstm_classifier import LSTMClassifier\n",
    "from models.gru_classifier import GRUClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('data/utterances.train')\n",
    "val = load_data('data/utterances.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09237789951132092"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, val]).sample(frac=1) # Merge train & val then shuffle\n",
    "val_split = len(val) / len(train)\n",
    "val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('data/utterances.test', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train['dialog_act'].unique()\n",
    "num_classes = len(classes)\n",
    "max_len = train['utterance_t'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (vocab, word_to_idx, idx_to_word) = process_data(train, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_vocab = [word for row in test['utterance_t'] for word in row if word not in vocab]\n",
    "for word in test_vocab:\n",
    "    idx = len(word_to_idx)\n",
    "    word_to_idx[word] = idx\n",
    "    idx_to_word[idx] = word\n",
    "    vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "with open('/projekte/slu/share/emb/glove.twitter.27B.50d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "        if word in vocab:\n",
    "            weights[word] = np.array(line[1:], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embds_path = '/projekte/slu/share/GoogleNews-vectors-negative300.bin' \n",
    "# weights = load_bin_vec(embds_path, word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = weights[random.choice(list(weights.keys()))].shape[0]\n",
    "add_unknown_words(weights, word_to_idx, k=num_dims, min_df=0)\n",
    "W, word_idx = get_W(weights, k=num_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GRUClassifier(num_classes, max_len, W)\n",
    "model = LSTMClassifier(num_classes, max_len, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_split=val_split * 2,\n",
    "                    epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('gru_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sequence.pad_sequences(test['utterance_t'].apply(process_seq, args=[word_idx]),\n",
    "                                maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       " array([8768,  296, 8321,    3,  375,  357,    4,   73,  539,   61,    2,\n",
       "          18,   49,   32,   58,   33,   19,    3,   73,  122,    7,    7,\n",
       "           7,    8,    6,  555,    3,   59,  141,    1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.unique(pred, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(pred, return_counts=True)\n",
    "pred_out = pd.Series(dict([(classes[i], c / len(pred))\n",
    "                           for i,c in list(zip(counts[0], counts[1]))]), name='dialog_act')\n",
    "train_out = (train.groupby('dialog_act').size() / len(train))\n",
    "merged = pd.DataFrame(data=dict(pred_out=pred_out, train_out=train_out)).dropna()\n",
    "merged['% dif'] = (merged['pred_out'] - merged['train_out']) * 10\n",
    "merged['rank dif'] = ((merged['pred_out'].rank() - merged['train_out']\n",
    "                       .rank())\n",
    "                       .abs()\n",
    "                       .astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_out</th>\n",
       "      <th>train_out</th>\n",
       "      <th>% dif</th>\n",
       "      <th>rank dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.43840</td>\n",
       "      <td>0.497256</td>\n",
       "      <td>-0.588564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.41605</td>\n",
       "      <td>0.195615</td>\n",
       "      <td>2.204352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.01785</td>\n",
       "      <td>0.074276</td>\n",
       "      <td>-0.564265</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>0.01875</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>-0.242242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%--</th>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.038933</td>\n",
       "      <td>-0.241327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba</th>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.024342</td>\n",
       "      <td>-0.206916</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qy</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>-0.219275</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.02695</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.101141</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bk</th>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>-0.130739</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qw</th>\n",
       "      <td>0.00305</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>-0.072686</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>-0.082668</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>-0.060026</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.027980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh</th>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>-0.047368</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs</th>\n",
       "      <td>0.00160</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>-0.028803</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc</th>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>-0.037923</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>-0.036600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qo</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.027678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qh</th>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>-0.019591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>0.00610</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qrr</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc</th>\n",
       "      <td>0.00705</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.060385</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3</th>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bd</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.004629</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aap</th>\n",
       "      <td>0.02775</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.270248</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>-0.005920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft</th>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_out  train_out     % dif  rank dif\n",
       "s     0.43840   0.497256 -0.588564         0\n",
       "b     0.41605   0.195615  2.204352         0\n",
       "aa    0.01785   0.074276 -0.564265         3\n",
       "%     0.01875   0.042974 -0.242242         1\n",
       "%--   0.01480   0.038933 -0.241327         2\n",
       "ba    0.00365   0.024342 -0.206916         4\n",
       "qy    0.00010   0.022028 -0.219275        22\n",
       "x     0.02695   0.016836  0.101141         4\n",
       "bk    0.00015   0.013224 -0.130739        18\n",
       "qw    0.00305   0.010319 -0.072686         2\n",
       "ar    0.00165   0.009917 -0.082668         5\n",
       "h     0.00245   0.008453 -0.060026         3\n",
       "d     0.00365   0.006448 -0.027980         2\n",
       "bh    0.00015   0.004887 -0.047368        13\n",
       "bs    0.00160   0.004480 -0.028803         2\n",
       "co    0.00020   0.004134 -0.039339         9\n",
       "bc    0.00030   0.004092 -0.037923         7\n",
       "2     0.00040   0.004060 -0.036600         2\n",
       "qo    0.00035   0.003118 -0.027678         3\n",
       "qh    0.00090   0.002859 -0.019591         1\n",
       "br    0.00610   0.001492  0.046081        12\n",
       "g     0.00290   0.001316  0.015836         8\n",
       "qrr   0.00035   0.001095 -0.007447         1\n",
       "cc    0.00705   0.001012  0.060385        16\n",
       "t3    0.00295   0.000933  0.020170        12\n",
       "bd    0.00095   0.000822  0.001278         8\n",
       "t1    0.00035   0.000813 -0.004629         5\n",
       "aap   0.02775   0.000725  0.270248        25\n",
       "fa    0.00005   0.000642 -0.005920         1\n",
       "ft    0.00015   0.000494 -0.003442         3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.sort_values(by='train_out', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% ['<START>', 'But', 'once', 'we', 'once', 'we', \"'ve\", 'done', 'the', 'intellectual', 'part', 'of', 'these', ',', 'uh', ',', 'we', 'can', 'just', 'knock', 'them', 'out', ',', 'right', '?', '<END>']\n",
      "s ['<START>', 'And', 'the', ',', 'uh', ',', 'Aurora', 'HTK', ',', 'it', 'was', 'like', 'twenty', '.', '<END>']\n",
      "s ['<START>', 'Mmm', '.', '<END>']\n",
      "b ['<START>', 'So', 'y', 'the', 'example', 'is', ',', '\"', 'That', 'would', 'be', 'hard', '\"', '<END>']\n",
      "%-- ['<START>', 'Well', ',', 'or', 'if', 'you', \"'re\", 'a', 'C', 'programmer', '.', '<END>']\n",
      "b ['<START>', 'if', 'they', \"'re\", 'right', 'next', 'to', 'one', 'another', '?', '<END>']\n",
      "s ['<START>', 'That', \"'s\", 'interesting', '.', '<END>']\n",
      "b ['<START>', 'I', \"'d\", 'expect', 'it', 'to', 'be', 'a', 'minor', 'effect', ',', '<END>']\n",
      "b ['<START>', 'Mmm', '?', '<END>']\n",
      "s ['<START>', 'Mm', '-', 'hmm', '.', '<END>']\n",
      "s ['<START>', 'Alright', '.', '<END>']\n",
      "b ['<START>', 'It', 'was', 'bo', 'it', 'both', 'times', 'the', 'same', 'person', '.', '<END>']\n",
      "b ['<START>', 'and', 'hopefully', 'these', 'features', 'w', 'would', 'help', '<END>']\n",
      "s ['<START>', 'But', 'only', 'to', 'play', '.', '<END>']\n",
      "s ['<START>', 'Yeah', '.', '<END>']\n",
      "s ['<START>', 'Sure', '.', '<END>']\n",
      "b ['<START>', 'As', 'I', 'said', 'before', ',', 'the', 'uh', 'using', 'Dan', \"'s\", ',', 'uh', ',', 'uh', ',', 'vocal', 'tract', 'normalization', 'option', 'works', 'very', 'well', '.', '<END>']\n",
      "b ['<START>', 'You', 'could', 'use', 'they', 'could', 'use', 'their', 'own', '.', '<END>']\n",
      "s ['<START>', 'Yeah', '.', '<END>']\n",
      "s ['<START>', 'Mm', '-', 'hmm', '.', '<END>']\n"
     ]
    }
   ],
   "source": [
    "for p, c in zip(pred[:20], test['utterance_t'].iloc[:20]):\n",
    "    print(classes[p], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_t-3</th>\n",
       "      <th>utterance_t-2</th>\n",
       "      <th>utterance_t-1</th>\n",
       "      <th>utterance_t</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bmr003_2578</th>\n",
       "      <td>I have to do</td>\n",
       "      <td>[&lt;START&gt;, that, 's, true, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, but, we, haven't, spent, that, ,, ri...</td>\n",
       "      <td>[&lt;START&gt;, But, once, we, once, we, 've, done, ...</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bro027_44</th>\n",
       "      <td>Um ,</td>\n",
       "      <td>[&lt;START&gt;, but, one, of, the, differences, that...</td>\n",
       "      <td>[&lt;START&gt;, Yep, ., &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, And, the, ,, uh, ,, Aurora, HTK, ,, ...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bro015_42</th>\n",
       "      <td>Oh so take a real VAD but apply it to to to th...</td>\n",
       "      <td>[&lt;START&gt;, Uh, g, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Yeah, ,, to, the, clean, and, take, ...</td>\n",
       "      <td>[&lt;START&gt;, Mmm, ., &lt;END&gt;]</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Btr002_235</th>\n",
       "      <td>boy , it 's hard to ig uh , ignoi that ignore ...</td>\n",
       "      <td>[&lt;START&gt;, Uh, -, huh, ., &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Um, ,, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, So, y, the, example, is, ,, \", That,...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bmr016_1398</th>\n",
       "      <td>In Monty Python you say \" argh \" a lot .</td>\n",
       "      <td>[&lt;START&gt;, Oh, yeah, ?, &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, So, ., &lt;END&gt;]</td>\n",
       "      <td>[&lt;START&gt;, Well, ,, or, if, you, 're, a, C, pro...</td>\n",
       "      <td>%--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  utterance_t-3  \\\n",
       "utterance_ID                                                      \n",
       "Bmr003_2578                                       I have to do    \n",
       "Bro027_44                                                 Um ,    \n",
       "Bro015_42     Oh so take a real VAD but apply it to to to th...   \n",
       "Btr002_235    boy , it 's hard to ig uh , ignoi that ignore ...   \n",
       "Bmr016_1398           In Monty Python you say \" argh \" a lot .    \n",
       "\n",
       "                                                  utterance_t-2  \\\n",
       "utterance_ID                                                      \n",
       "Bmr003_2578                    [<START>, that, 's, true, <END>]   \n",
       "Bro027_44     [<START>, but, one, of, the, differences, that...   \n",
       "Bro015_42                               [<START>, Uh, g, <END>]   \n",
       "Btr002_235                      [<START>, Uh, -, huh, ., <END>]   \n",
       "Bmr016_1398                       [<START>, Oh, yeah, ?, <END>]   \n",
       "\n",
       "                                                  utterance_t-1  \\\n",
       "utterance_ID                                                      \n",
       "Bmr003_2578   [<START>, but, we, haven't, spent, that, ,, ri...   \n",
       "Bro027_44                              [<START>, Yep, ., <END>]   \n",
       "Bro015_42     [<START>, Yeah, ,, to, the, clean, and, take, ...   \n",
       "Btr002_235                              [<START>, Um, ,, <END>]   \n",
       "Bmr016_1398                             [<START>, So, ., <END>]   \n",
       "\n",
       "                                                    utterance_t prediction  \n",
       "utterance_ID                                                                \n",
       "Bmr003_2578   [<START>, But, once, we, once, we, 've, done, ...          %  \n",
       "Bro027_44     [<START>, And, the, ,, uh, ,, Aurora, HTK, ,, ...          s  \n",
       "Bro015_42                              [<START>, Mmm, ., <END>]          s  \n",
       "Btr002_235    [<START>, So, y, the, example, is, ,, \", That,...          b  \n",
       "Bmr016_1398   [<START>, Well, ,, or, if, you, 're, a, C, pro...        %--  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['prediction'] = [classes[p] for p in pred]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3372489_sorensen_topic1_result.txt', 'w') as fout:\n",
    "    for idx, p in test['prediction'].iteritems():\n",
    "        fout.write(f'{idx} {p}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

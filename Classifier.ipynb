{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import keras\n",
    "from utils import *\n",
    "from models.lstm_classifier import LSTMClassifier\n",
    "from models.gru_classifier import GRUClassifier\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('data/utterances.train')\n",
    "val = load_data('data/utterances.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09237789951132092"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, val]).sample(frac=1) # Merge train & val then shuffle\n",
    "val_split = len(val) / len(train)\n",
    "val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('data/utterances.test', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train['dialog_act'].unique()\n",
    "num_classes = len(classes)\n",
    "max_len = train['utterance_t'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (vocab, word_to_idx, idx_to_word) = process_data(train, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_vocab = [word for row in test['utterance_t'] for word in row if word not in vocab]\n",
    "for word in test_vocab:\n",
    "    idx = len(word_to_idx)\n",
    "    word_to_idx[word] = idx\n",
    "    idx_to_word[idx] = word\n",
    "    vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "with open('/projekte/slu/share/emb/glove.twitter.27B.50d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        weights[line[0]] = np.array(line[1:], dtype='float32')\n",
    "del weights['0.45973'] # Corrects an error in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embds_path = '/projekte/slu/share/GoogleNews-vectors-negative300.bin' \n",
    "# weights = load_bin_vec(embds_path, word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = weights[random.choice(list(weights.keys()))].shape[0]\n",
    "add_unknown_words(weights, word_to_idx, k=num_dims, min_df=0)\n",
    "W, word_idx = get_W(weights, k=num_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUClassifier(num_classes, max_len, W)\n",
    "#model = LSTMClassifier(num_classes, max_len, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 106, 50)           60195350  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               44160     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 31)                2015      \n",
      "=================================================================\n",
      "Total params: 60,254,197\n",
      "Trainable params: 60,254,069\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('lstm_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176502 samples, validate on 40000 samples\n",
      "Epoch 1/3\n",
      " 63616/176502 [=========>....................] - ETA: 11:16 - loss: 1.7006 - acc: 0.5951"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_split=val_split * 2,\n",
    "                    epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_model_google.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sequence.pad_sequences(test['utterance_t'].apply(process_seq, args=[word_idx]),\n",
    "                                maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(pred, return_counts=True)\n",
    "for i,c in zip(counts[0], counts[1]):\n",
    "    print(classes[i], c / len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train.groupby('dialog_act').size() / len(train)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, c in zip(pred[:20], test['utterance_t'].iloc[:20]):\n",
    "    print(classes[p], c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
